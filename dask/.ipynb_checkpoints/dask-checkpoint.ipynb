{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244dd0ca",
   "metadata": {},
   "source": [
    "![dask.png](dask.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import LocalCluster, Client\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427862e0-8bf0-4e53-bf42-e75e45dfd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The jupyter notebook is launched from your $HOME directory.\n",
    "# Change the working directory to the workshop directory\n",
    "# which was created in your username directory under /scratch/vp91\n",
    "os.chdir(os.path.expandvars(\"/scratch/vp91/$USER/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9df83",
   "metadata": {},
   "source": [
    "### Dask Collections\n",
    "\n",
    "* **High-level collections**: Mimic NumPy, lists, and pandas but can operate in parallel on datasets that don’t fit into memory \n",
    "    * Array\n",
    "    * DataFrame\n",
    "    * Bag\n",
    "    \n",
    "* **Low-level collections**: Give finer control to build custom parallel and distributed computations\n",
    "    * Delayed\n",
    "    * Futures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f229f3",
   "metadata": {},
   "source": [
    "# Dask Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba32bea",
   "metadata": {},
   "source": [
    "![dataframe.png](dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a4c6e",
   "metadata": {},
   "source": [
    "* One Dask DataFrame is comprised of many in-memory pandas DataFrames separated along the index. \n",
    "* One operation on a Dask DataFrame triggers many pandas operations on the constituent pandas DataFrames \n",
    "* These operations are mindful of potential parallelism and memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/nycflights/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d43b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the csv file into a single Dask dataframe\n",
    "ddf = dd.read_csv(\n",
    "    os.path.join(\"data\", \"nycflights\", \"*.csv\"), parse_dates={\"Date\": [0, 1, 2]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265cc6cc",
   "metadata": {},
   "source": [
    "* dask.dataframe.read_csv only reads in a sample from the beginning of the file\n",
    "* These inferred datatypes are then enforced when reading all partitions\n",
    "* Sometimes, datatypes inferred in the sample can be incorrect. \n",
    "    * The first n rows have no value for CRSElapsedTime (which pandas infers as a float), and later on turn out to be strings (object dtype). \n",
    "\n",
    "* Good practice - specify dtypes directly using the dtype keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv(\n",
    "    os.path.join(\"data\", \"nycflights\", \"*.csv\"),\n",
    "    parse_dates={\"Date\": [0, 1, 2]},\n",
    "    dtype={\"TailNum\": str, \"CRSElapsedTime\": float, \"Cancelled\": bool},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dff91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755783fc",
   "metadata": {},
   "source": [
    "### Lazy evaluation\n",
    "* Representation of the DataFrame object contains no data \n",
    "* Dask has just done enough to read the start of the first file, and infer the column names and dtypes\n",
    "\n",
    "* Dask **constructs** the logic (called task graph) of your computation immediately\n",
    "* **Evaluates** them only when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87245763",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf78a9",
   "metadata": {},
   "source": [
    "* Functions like len, head, tail also trigger an evaluation.\n",
    "    * load actual data, (that is, load each file into a pandas DataFrame)\n",
    "    * apply the corresponding functions to each pandas DataFrame (also known as a partition)\n",
    "    * combine the subtotals to give you the final grand total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a98b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb19168",
   "metadata": {},
   "source": [
    "### Operation on multiple files in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ab5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# find the max value of the DepDelay coulmn in all the 10 dataframes\n",
    "files = os.listdir(os.path.join('data', 'nycflights'))\n",
    "maxes = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join('data', 'nycflights', file))\n",
    "    maxes.append(df.DepDelay.max())\n",
    "\n",
    "final_max = max(maxes)\n",
    "print(final_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f3c18e",
   "metadata": {},
   "source": [
    "### Operation on multiple files in Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max value of the DepDelay coulmn in all the 10 dataframes\n",
    "# This only creates the task graph, it does not execute the operation\n",
    "result = ddf.DepDelay.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1dd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9affd4",
   "metadata": {},
   "source": [
    "### Excercise: Find the number of flight from each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc668f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46c3b859",
   "metadata": {},
   "source": [
    "* We can also combine multiple compute steps into a single instruction\n",
    "* This is usualy more efficient\n",
    "    * Task graphs for both results are merged when calling dask.compute\n",
    "    * shared operations to only be done once instead of twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb276f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_canceled = ddf[~ddf.Cancelled]\n",
    "mean_delay = non_canceled.DepDelay.mean()\n",
    "std_delay = non_canceled.DepDelay.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mean_delay_res = mean_delay.compute()\n",
    "std_delay_res = std_delay.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mean_delay_res, std_delay_res = dask.compute(mean_delay, std_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4dab9",
   "metadata": {},
   "source": [
    "# Dask  Arrays - parallelized numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed090fb",
   "metadata": {},
   "source": [
    "![arrays.png](arrays.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcec49c",
   "metadata": {},
   "source": [
    "* Dask Array implements a subset of the NumPy ndarray interface using **blocked** algorithms\n",
    "* Large array is cut into many small arrays\n",
    "* Large computations are performed by combining many smaller computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NumPy array\n",
    "a_np = np.ones(10)\n",
    "a_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how a blocked operation is done in numpy. We divide the whole ndarray\n",
    "# of size 10 int slices of 2, each of size 5\n",
    "\n",
    "a_np_sum = a_np[:5].sum() + a_np[5:].sum()\n",
    "a_np_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask array\n",
    "\n",
    "# In task ndarray we specify the slices usinh the keyword chunk. \n",
    "# chunk defines the numer of elements in each slice\n",
    "\n",
    "a_da = da.ones(10, chunks=5)\n",
    "a_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_da_sum = a_da.sum()\n",
    "a_da_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_da_sum.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e919e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_da_sum.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65fc0b",
   "metadata": {},
   "source": [
    "* Dask can also find an optimal chunk by itself\n",
    "* If your chunks are too small\n",
    "    * the amount of actual work done by every task is very tiny\n",
    "    * the overhead of coordinating all these tasks results in a very inefficient process\n",
    "* If your chunks are too big\n",
    "    * you will likely run out of memory\n",
    "    * data will have to be moved to the disk \n",
    "    * this will lead to performance decrements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4985f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xd = da.random.normal(10, 0.1, size=(30_000, 30_000), chunks=(3000, 3000)) # We specify the chunk\n",
    "yd = xd.mean(axis=0)\n",
    "yd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d124a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xd = da.random.normal(10, 0.1, size=(30_000, 30_000)) # Dask finds the chunk\n",
    "yd = xd.mean(axis=0)\n",
    "yd.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eb1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.chunksize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac0a72",
   "metadata": {},
   "source": [
    "# Delayed decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9d04a",
   "metadata": {},
   "source": [
    "* A Block of code can have operations that can happen in parallel\n",
    "* Normally in python these operation will happen sequentially\n",
    "    * Or the user will identify the parallel section and write parallel codes\n",
    "* The Dask **delayed** function decorates your functions so that they operate lazily \n",
    "* Dask will defer execution of the function, placing the function and its arguments into a task graph\n",
    "* Dask will then identify oppurtunities for parallelism in the task graph\n",
    "* The Dask schedulers will exploit this parallelism, generally improving performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fca403",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def inc(x):\n",
    "    time.sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78533de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb953074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the two increments are independent of each other, we can run them in parallel\n",
    "\n",
    "x = inc(1)\n",
    "y = inc(2)\n",
    "z = add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e28b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here Z is a delayed object\n",
    "\n",
    "z.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9acd56",
   "metadata": {},
   "source": [
    "# Dask future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137e5c4",
   "metadata": {},
   "source": [
    "* we can submit individual functions for evaluation\n",
    "* The call returns immediately, giving one or more future\n",
    "    * whose status begins as “pending”\n",
    "    * later becomes “finished”\n",
    "* There is no **blocking** of the local Python session.\n",
    "\n",
    "* Difference between futures and delayed\n",
    "    * delayed is lazy (it just constructs a graph) \n",
    "    * futures are eager. \n",
    "    * With futures, as soon as the inputs are available and there is compute available, the computation starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61751b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=4)\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def double(x):\n",
    "    sleep(2)\n",
    "    return 2 * x\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = client.submit(inc, 1)  # returns immediately with pending future\n",
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98103a85",
   "metadata": {},
   "source": [
    "If we check the future after a few seconds we can see that it is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07115235",
   "metadata": {},
   "outputs": [],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e497a-367b-4202-a943-435ff21670ee",
   "metadata": {},
   "source": [
    "## Compute Vs Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d291e-946f-4614-8f86-1d81c4287969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask.datasets.timeseries()\n",
    "df.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbea6e-cc5b-4151-9fff-8fb24dceb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780d77a-af72-4680-8c4c-b7c65a9c0a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_df = df.compute()\n",
    "type(computed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7cf48-b48f-4b4c-9cf2-0c9703edc9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persist = df.persist()\n",
    "type(df_persist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50d55f0-e9c1-4448-bce3-945c31b1a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persist.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe47e1-5ae6-4297-97d3-f247d34d2e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
